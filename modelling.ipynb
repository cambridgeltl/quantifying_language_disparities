{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea97e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Example input (JSON entry in model_performance_record_list.json)\n",
    "# [\n",
    "#   {\"Model\": \"gpt-3.5-turbo\", \"Language\": \"en\", \"Score\": 97.8, \"Dataset\": \"xcopa\", \"Metric\": \"accuracy\"},\n",
    "#   ...\n",
    "# ]\n",
    "\n",
    "# df = pd.read_json(\"model_performance_record_list.json\")\n",
    "\n",
    "df = pd.read_json(\"./model_performance_record_list.json\")\n",
    "df = df[df[\"Language\"] != \"avg\"]\n",
    "\n",
    "df[\"Setup\"] = df[\"Dataset\"] + \"_\" + df[\"Metric\"]\n",
    "for col in [\"Language\", \"Setup\", \"Model\"]:\n",
    "    df[col] = df[col].astype(\"category\")\n",
    "\n",
    "md = smf.mixedlm(\"Score ~ C(Language) + C(Setup)\", df, groups=df[\"Model\"], re_formula=\"~1\")\n",
    "mdf = md.fit(method=\"lbfgs\", reml=False)\n",
    "\n",
    "intercept = mdf.params[\"Intercept\"]\n",
    "language_effect = mdf.params.filter(like=\"C(Language)\").to_dict()\n",
    "setup_effect = mdf.params.filter(like=\"C(Setup)\").to_dict()\n",
    "mean_setup_effect = np.mean(list(setup_effect.values()))\n",
    "\n",
    "def beta_lang(lang): return language_effect.get(f\"C(Language)[T.{lang}]\", 0.0)\n",
    "def beta_setup(setup): return setup_effect.get(f\"C(Setup)[T.{setup}]\", 0.0)\n",
    "\n",
    "lang_setup_potential = {\n",
    "    (lang, stp): intercept + beta_lang(lang) + beta_setup(stp)\n",
    "    for (lang, stp) in df[[\"Language\", \"Setup\"]].drop_duplicates().itertuples(index=False)\n",
    "}\n",
    "df[\"Potential\"] = df.apply(lambda r: lang_setup_potential[(r.Language, r.Setup)], axis=1)\n",
    "\n",
    "language_potential = {\n",
    "    lang: intercept + beta_lang(lang) + mean_setup_effect\n",
    "    for lang in df[\"Language\"].cat.categories\n",
    "}\n",
    "language_df = (\n",
    "    pd.DataFrame(language_potential.items(), columns=[\"Language\", \"Potential\"])\n",
    "      .sort_values(\"Potential\", ascending=False)\n",
    ")\n",
    "\n",
    "df[\"PRR\"] = df[\"Score\"].astype(float) / df[\"Potential\"]\n",
    "\n",
    "model_evaluation = df.groupby(\"Model\")[\"PRR\"].agg(mean_prr=\"mean\", std_prr=\"std\").assign(\n",
    "    cv_prr=lambda x: x[\"std_prr\"] / x[\"mean_prr\"]\n",
    ").reset_index()\n",
    "\n",
    "print(\"Language Potential\")\n",
    "print(language_df.to_string(index=False))\n",
    "\n",
    "print(\"Model-level Evaluation\")\n",
    "print(model_evaluation.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc('font', **{'family': 'serif', 'serif': ['Palatino'], 'size': 18})\n",
    "rc('text', usetex=True)\n",
    "mpl.rcParams.update({'errorbar.capsize': 6})\n",
    "plt.rcParams[\"figure.figsize\"] = [8, 6]\n",
    "\n",
    "df = pd.DataFrame(model_evaluation)\n",
    "\n",
    "\n",
    "llm_models = [\n",
    "    'BLOOMZ', 'text-davinci-003', 'text-davinci-003 (TT)',\n",
    "    'gpt-3.5-turbo', 'gpt-3.5-turbo (TT)', 'gpt-4-32k', 'gpt-4-32k (TT)'\n",
    "]\n",
    "finetuned_models = [\n",
    "    'MuRIL', 'TuLRv6 - XXL', 'XGLM', 'XLM-R Large', 'mBERT', 'mT5-Base'\n",
    "]\n",
    "\n",
    "def get_category(model_name):\n",
    "    if model_name in llm_models:\n",
    "        return 'LLM with ICL'\n",
    "    elif model_name in finetuned_models:\n",
    "        return 'Fine-tuned'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['Category'] = df['Model'].apply(get_category)\n",
    "\n",
    "palette = {'LLM with ICL': sns.color_palette(\"colorblind\")[0],\n",
    "           'Fine-tuned': sns.color_palette(\"colorblind\")[1]}\n",
    "markers = {'LLM with ICL': 'o', 'Fine-tuned': '^'}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for category, group in df.groupby('Category'):\n",
    "    ax.scatter(\n",
    "        group[\"mean_prr\"],\n",
    "        group[\"cv_prr\"],\n",
    "        color=palette[category],\n",
    "        marker=markers[category],\n",
    "        edgecolor='black',\n",
    "#         s=60,\n",
    "        label=category\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "texts = []\n",
    "for i, row in df.iterrows():\n",
    "    texts.append(\n",
    "        ax.text(row[\"mean_prr\"], row[\"cv_prr\"], r'\\textsc{%s}' % row[\"Model\"], fontsize=16)\n",
    "    )\n",
    "\n",
    "\n",
    "adjust_text(texts, ax=ax, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "\n",
    "old_x, old_y = texts[6].get_position()\n",
    "texts[6].set_position((old_x - 0.25, old_y+0.025))\n",
    "ax.set_xlabel(r'\\textbf{Mean-PRR (Performance Realisation Ratio)}', fontsize=18)\n",
    "ax.set_ylabel(r'\\textbf{CV-PRR (Language Disparity)}', fontsize=18)\n",
    "ax.grid(True, linestyle='--')\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.legend(title=\"Model Type\", fontsize=14, title_fontsize=15, loc='upper right')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}